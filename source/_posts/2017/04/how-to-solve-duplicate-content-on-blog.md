---
author:
  nick: Unknown
  link: ""
  email: noreply@blogger.com
category:
  - Uncategorized
comments: true
cover: https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcQa1lm1EI1a4kQStyHaoRq2LTQ3iHdj3CuE8YfEqS3-jKcycvJfOP44cSUy_A
date: 2017-04-23T16:00:00.000+07:00
lang: en
location: ""
modified: 2017-04-23T16:00:13.899+07:00
subtitle: How To Solve Duplicate Content On Blog Duplicate content is to
  duplicate the title and description of the content in a blog which is
tags:
  - Blogger
title: How To Solve Duplicate Content On Blog
type: post
uuid: 1174149a-9f43-4888-8a83-c0005fc2644c
webtitle: WMI Gitlab
updated: 2017-04-23T16:00:13+07:00
thumbnail: https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcQa1lm1EI1a4kQStyHaoRq2LTQ3iHdj3CuE8YfEqS3-jKcycvJfOP44cSUy_A
photos:
  - https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcQa1lm1EI1a4kQStyHaoRq2LTQ3iHdj3CuE8YfEqS3-jKcycvJfOP44cSUy_A
description: How To Solve Duplicate Content On Blog Duplicate content is to
  duplicate the title and description of the content in a blog which is
excerpt: How To Solve Duplicate Content On Blog Duplicate content is to
  duplicate the title and description of the content in a blog which is
wordcount: 1533
---

<div dir="ltr" style="text-align: left;" trbidi="on"><h2> How To Solve Duplicate Content On Blog </h2><div class="separator" style="clear: both; text-align: center;"><a href="https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcQa1lm1EI1a4kQStyHaoRq2LTQ3iHdj3CuE8YfEqS3-jKcycvJfOP44cSUy_A" imageanchor="1" style="margin-left: 1em; margin-right: 1em;" rel="noopener noreferer nofollow"><img border="0" src="https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcQa1lm1EI1a4kQStyHaoRq2LTQ3iHdj3CuE8YfEqS3-jKcycvJfOP44cSUy_A"></a></div><div><br></div><div><strong>Duplicate content</strong> is to duplicate the title and description of the content in a blog which is  caused by the emergence of two or more URLs, but leads to a page or the  same content. Duplicate content may also occur as a result of an article in  Copas from other blogs and published again, even though the URL is  different but the title and its contents remain the same without any  modification is said to duplicate it contains. Duplicate content should be  avoided as the scatter machines or engines really do not like pengandaan  content.  <br><br><strong>Why Search Engines do not like duplicate content?</strong> <br><blockquote>Search Engines do not like duplicate content for Search Engine will be   difficult and confused select or specify which content should be in the   index and appear in search engines.  </blockquote><strong>And Duplicate Content How to Overcome itself?</strong> <br><strong>  <br> </strong> One way to deal with duplicate content is not lazy to make the article, it  means do not copy and paste articles published people to return to your  blog because it was futile and extremely detrimental to those who make the  article itself.So make original content for the search engines love  articles that are original made your own.  <br><br>Another method that can be applied in your blog to avoid duplicate content  is as follows:  <br><br><br><ul><li>   Duplicate content caused by the blog archives.   </li></ul><br>examples from the archives blog url:  <br><blockquote><em>http://yourblog.blogspot.com/2015_03_01_archive.html</em> </blockquote>if the url is in the index, there will be duplicate contains.  <br>to fix this please put the meta tag below under the &lt;head&gt;  <br><blockquote>&lt;b: if cond = 'data: blog.pageType == &amp; quot; archive &amp;   quot;'&gt; &lt;meta content = "noindex, nofollow 'name =' robots '/&gt;   &lt;meta content =" noindex, nofollow' name = 'Googlebot' /&gt; &lt;/   b: if&gt;  </blockquote><em><u>Or it could also activate custom robots header tags.</u></em> <br><br>how to open the "Settings"&gt; "search preferences will" enable plainly  "Custom robots header tags" and menyetingnya like image below:<br><table align="center" cellpadding="0" cellspacing="0">  <tbody><tr>    <td><a href="http://2.bp.blogspot.com/-uE-asOXXJ0Y/VSKhJbwmxpI/AAAAAAAAA40/kRpiuJRtVMc/s1600/cara%2Bmengatasi%2Bduplikat%2Bkonten%2Bdi%2Bblog.png" rel="noopener noreferer nofollow">      <img alt="Cara Mengatasi Duplikat Konten Di Blog" border="0" height="255" src="https://2.bp.blogspot.com/-uE-asOXXJ0Y/VSKhJbwmxpI/AAAAAAAAA40/kRpiuJRtVMc/s400/cara%2Bmengatasi%2Bduplikat%2Bkonten%2Bdi%2Bblog.png" title="How To Solve Duplicate Content On Blog" width="400">     </a>    </td>   </tr><tr>    <td>Custom robots header tags      </td>   </tr></tbody> </table><ul><li>   Duplicate content caused by label blog   </li></ul><br>examples of label blog url:  <br><blockquote>http://yourblog.blogspot.com/search/label/blogging  </blockquote>together with problems in the archives of the blog if the URL in the index  then there is duplicate content.  <br>how to overcome them by putting meta TEG below under the &lt;head&gt;  <br><blockquote>&lt;b: if cond = 'data: blog.pageType == &amp; quot; index &amp;   quot;'&gt; &lt;b: if cond = 'data: blog.searchLabel'&gt; &lt;meta   content = "noindex, nofollow 'name =' robots' /&gt; &lt;meta content =   "noindex, nofollow 'name =' googlebot '/&gt; &lt;/ b: if&gt; &lt;/ b:   if&gt;  </blockquote><br><br><ul><li>   The last way is to put a meta tag below under the &lt;head&gt;   </li></ul><blockquote>&lt;link expr: href = 'data: blog.url' rel = 'canonical' /&gt;  </blockquote><br>goal to put the meta TEG is to instruct the only search engine to index a  page url that is uncharacteristic course.  <br><br><br><ul><li>   Duplicate content caused by the blog page in the open from the    mobile version.   </li></ul>To cope with robots.txt activate and store the code below in your  robots.txt.  <br><blockquote>User-agent: Mediapartners-Google   <br>Disallow:   <br>User-agent: Googlebot   <br>Disallow: / search   <br>Disallow: /? M = 1   <br>Disallow: /? M = 0   <br>Disallow: / *? M = 1   <br>Disallow: / *? M = 0   <br>User-agent: *   <br>Disallow: / search   <br>Sitemap:   http://urlbloganda.blogspot.com/feeds/posts/default?orderby=UPDATED  </blockquote>This method is very helpful in addressing duplicate content but you must be  careful or consider using this way because this way is not very mobile  friendly.  <br>robots.txt this section is not mobile-friendly:  <br><blockquote>Disallow: /? M = 1  </blockquote><blockquote>Disallow: /? M = 0  </blockquote><blockquote>Disallow: / *? M = 1  </blockquote><blockquote>Disallow: / *? M = 0  </blockquote>meaning your content will not be in the index in the mobile version that  causes a decrease in traffic to your blog.  <br><br>Those are some ways to cope with duplicate content on your blog. </div></div>